<!DOCTYPE html>
<html><head lang="en"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>AiSDF</title>



    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://Epsilon8854.github.io/AiSDF/img/teaser.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="9764">
    <meta property="og:image:height" content="4567">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://Epsilon8854.github.io/AiSDF">
    <meta property="og:title" content="AiSDF: Structure-aware Neural Signed Distance Fields in Indoor Scenes">
    <meta property="og:description" content="We introduce blah">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="AiSDF: Structure-aware Neural Signed Distance Fields in Indoor Scenes">
    <meta name="twitter:description" content="We introduce blah">
    <meta name="twitter:image" content="https://Epsilon8854.github.io/AiSDF/img/teaser.png">


    <!-- mirror: F0%9F%AA%9E&lt -->
    <link rel="icon" href="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text y=%22.9em%22 font-size=%2290%22&gt;%E2%9C%A8&lt;/text&gt;&lt;/svg&gt;">
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">
    <link rel="stylesheet" href="css/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <script src="js/jquery.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/codemirror.min.js"></script>
    <script src="js/clipboard.min.js"></script>
    <script src="js/video_comparison.js"></script>
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="header" style="text-align: center; margin: auto;">
        <div class="row" id="title-row" style="max-width: 100%; margin: 0 auto; display: inline-block">
            <h2 class="col-md-12 text-center" id="title">
                <b>AiSDF</b>: Structure-aware Neural Signed Distance Fields in Indoor Scenes<br>
                 <small>
                    IEEE Robotics and Automation Letters (RA-L)
                </small>
            </h2>
        </div>
        
        <div class="row mt-3">
            <div class="col-md-2"></div>
            <!-- <div class="col text-center"> -->
                <a href="https://github.com/Syniez">
                    Inha Lee
                </a><sup>1, *</sup>
            <!-- </div> -->
            <!-- <div > -->
                <div class="col-md-2"></div>
                <a href="https://threedv.github.io">
                    Jaehoon Jang
                </a><sup>1, *</sup>
            <!-- </div> -->
            <!-- <div class="col text-center"> -->
                <div class="col-md-2"></div>
                <a href="https://github.com/Jeongin-park">
                    Minje Kim
                </a><sup>1</sup>
            <!-- </div> -->
            <!-- <div class="col text-center"> -->
                <div class="col-md-2"></div>
                <a href="https://github.com/kimkj38">
                    Kyungdon Joo
                </a><sup>1</sup>
            <!-- </div> -->
            <div class="col-md-2"></div>
        </div>
        <div class="col text-center">
            <span><sup>1</sup> Ulsan National Institute of Science & Technology &nbsp;&nbsp;</span>
        </div>
        <div class="col text-center">
            <span><sup>*</sup> Equal contribution (alphabet order) &nbsp;&nbsp;</span>
        </div>
    </div>
    <script>
        document.getElementById('author-row').style.maxWidth = document.getElementById("title-row").clientWidth + 'px';
    </script>
    <div class="container" id="main">
        <div class="row">
                <div class="col-sm-12 col-sm-offset-1 text-center">
		
                    <ul class="list-unstyled">
                        <li class="col-sm-2 ">
                            <a href="https://github.com/AiSDF/AiSDF.github.io/raw/main/AiSDF_paper.pdf">
                            <img src="./img/paper_image.jpg" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <!-- <li class="col-sm-2">
                            <a href="https://youtu.be/S071rGezdNM">
                            <img src="./img/youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li> -->
                        <!-- <li class="col-sm-2">
                            <a href="https://drive.google.com/drive/folders/1jNpwAv1T1ntjIHUMJ1wABePA2Z8_nRRQ?usp=sharing" target="_blank">
                            <image src="img/database_icon.png" height="60px">
                                <h4><strong>NeRF Dataset</strong></h4>
                            </a>
                        </li>                           -->
                        <li class="col-sm-2">
                            <a href="https://github.com/AiSDF/AiSDF" target="_blank">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code(comming soon)</strong></h4>
                            </a>
                        </li>
			<!-- <li class="col-sm-2">
                            <a href="https://github.com/AiSDF/AiSDF.github.io/raw/main/AiSDF_supplementary.pdf" target="_blank">
                            <image src="img/supplementary_icon.png" height="60px">
                                <h4><strong>Supplementary Material</strong></h4>
                            </a>
                        </li>	 -->
                    </ul>
                </div>
        </div>

	<div class="row">
            <div class="col-md-8 col-md-offset-2">
                
                <div class="text-center">
                    
                        <img src="./img/teaser.jpg" width="100%">
                   
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Indoor scenes we are living in are visually homogenous or textureless, while they inherently have structural forms and provide enough structural priors for 3D scene reconstruction. Motivated by this fact, we propose a structure-aware online signed distance fields (SDF) reconstruction framework in indoor scenes, especially under the Atlanta world (AW) assumption. Thus, we dub this incremental SDF reconstruction for AW as AiSDF. Within the online framework, we infer the underlying Atlanta structure of a given scene and then estimate planar surfel regions supporting the Atlanta structure. This Atlanta-aware surfel representation provides an explicit planar map for a given scene. In addition, based on these Atlanta planar surfel regions, we adaptively sample and constrain the structural regularity in the SDF reconstruction, which enables us to improve the reconstruction quality by maintaining a high-level structure while enhancing the details of a given scene. We evaluate the proposed AiSDF on the ScanNet and ReplicaCAD datasets, where we demonstrate that the proposed framework is capable of reconstructing fine details of objects implicitly, as well as structures explicitly in room-scale scenes.
                </p>
            </div>
        </div>
	
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Surface Field
                </h3>
		<br>
                <div class="text-center">
                    <img src="./img/overview.png" width="100%">
                </div>
                <br>

                
            </div>
        </div>
	<div class="row">
	<div class="col-md-8 col-md-offset-2">
                <h3>
                    Energy-based Optimization
                </h3>
                <div class="text-justify">
                    By utilizing surface fields, we perform an energy-based optimization to find the optimal rigid registration to align target object in a pair of scenes. Our loss function consists of <i> Keypoint Energy</i> and <i>Matching Energy</i>. Keypoint energy provides an initial approximate solution by minimizing the ditance between manually annotated keypoint coordinates, and is then gradually annealed through the optimization. The robust matching energy compares the surface field of the two scenes on an active set of samples, given the current estimate of the rigid transform. To make the comparison robust to outliers, we utilize a robust kernel  <img src="./img/kappa.jpg"> and apply it on our residuals.
                    
                    <br><br>
                    
                </div>
		<br>
                <div class="text-center">
                    <img src="./img/matching_energy.jpg" width="50%">
                </div>
                <br>
		<div class="text-justify">
                    
                    Performing gradient-based optimization on a field with a co-domain of {0,1} is challenging, hence we smooth the surface field by convolving the categorical
field with a zero-mean Gaussian of isotropic covariance matrix <img src="./img/cov.jpg">, and derive <img src="./img/smooth_surface.jpg">. The residual is then efined using this smooth surface field:
                    <br><br>
                    
                </div>
		<br>
                <div class="text-center">
                    <img src="./img/residual_formula.jpg" width="50%">
                </div>
                <br>
		<div class="text-center">
                    <video id="refdir" width="100%" playsinline autoplay loop muted>
                        <source src="video/surfacevssmooth.mp4" type="video/mp4" />
                    </video>
                </div>
		
            </div>
        </div>	
 	<div class="row">
	<div class="col-md-8 col-md-offset-2">
                <h3>
                    Sampling
                </h3>
                <div class="text-justify">
                   A Metropolis-Hastings sampling algorithm is used to iteratively update set of samples. The sample set is initializaed by the keypoints and every N=20 iterations is updated by adding uniform noise to current set and accepting new points that are <i> in close correspondence</i>, <i> not too close to current set of samples </i> and <i> are close to surface</i>.
                    <br><br>
                    
                </div>
                <br>
		
		<table>
		    <tr >
			<td>
			   <video class="video" id="s1"  width="100%"  loop playsinline autoPlay muted src="video/lego_all.mp4" onplay="resizeAndPlay(this)"></video>
			  
		       </td>
			<td>
			    <video class="video" id="s2"  width="100%"  loop playsinline autoPlay muted src="video/pip_all.mp4" onplay="resizeAndPlay(this)"></video>
		       </td>
		     
		    </tr >
		    
		</table>
            </div>
        </div>	
        <div class="row">
	<div class="col-md-8 col-md-offset-2">
                <h3>
                    Results
                </h3>
		<div class="text-justify">
                  Registration results:
                    
                </div>
		<table>
		    <tr >
			<td>
			   <video class="video" id="reg1"  width="100%"  loop playsinline autoPlay muted src="video/31_vid.mp4" onplay="resizeAndPlay(this)"></video>
                   	   <canvas height=0 class="videoMerge" id="reg1Merge"></canvas>
				
			  
		       </td>
			<!-- <td>
			   <video class="video" id="reg2"  width="100%"  loop playsinline autoPlay muted src="video/bust.mp4" onplay="resizeAndPlay(this)"></video>
                   	   <canvas height=0 class="videoMerge" id="reg2Merge"></canvas>
			   

		       </td>
			<td>
			   <video class="video" id="reg3"  width="100%"  loop playsinline autoPlay muted src="video/jar.mp4" onplay="resizeAndPlay(this)"></video>
                   	   <canvas height=0 class="videoMerge" id="reg3Merge"></canvas>
			   
		       </td> -->
		     
		    </tr >
		    
		</table>
		<table width="100%" style="table-layout:fixed"><tr><td style="text-align:center" width="33%">Bench</td><td style="text-align:center" width="33%">Bust</td><td style="text-align:center" width="33%">Jar</td></tr></table>
           	
        	<br>
		<div class="text-justify">
                  Comparison to <a href="http://vladlen.info/papers/fast-global-registration.pdf">Fast Global Registration</a> applied to point clouds extracted from NeRF estimated depth map:
                    
                </div>
                <br>
		<div class="text-center">
                    <video id="refdir" width="100%" playsinline autoplay loop muted>
                        <source src="video/FGR_comparison.mp4" type="video/mp4" />
                    </video>
                </div>
                <div class="text-justify">
                   Registration iterations:
                    
                </div>
                <br>
		<div class="text-center">
                    <video id="refdir" width="100%" playsinline autoplay loop muted>
                        <source src="video/iterations.mp4" type="video/mp4" />
                    </video>
                </div>
		<div class="text-justify">
                   Ablation Study:
                    
                </div>
                <br>
		<div class="text-center">
                    <video id="refdir" width="100%" playsinline autoplay loop muted>
                        <source src="video/ablations.mp4" type="video/mp4" />
                    </video>
                </div>	
            </div>
        </div>	
        
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://youtube.com/embed/S071rGezdNM" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>    
       
            
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>

  title= AiSDF: Structure-aware Neural Signed Distance Fields in Indoor Scenes
  author= Inha, Lee and jaehoon, Jang and Minje, Kim and Kyungdon Joo
  journal= IEEE Robotics and Automation Letters, 2024
  year={2024}
</textarea>
                </div>
            </div>
        </div>
	

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    <br>
                The website template was borrowed from <a href="https://dorverbin.github.io/refnerf/">Dor Verbin</a>.
                </p>
            </div>
        </div>
    </div>


</body></html>
